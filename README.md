# ETL - Extração de API do Zero

**📅 Data:** 17 de dezembro  
**🕒 Horário:** 19h30 (Horário de Brasília)  
**📍 Local:** Online (YouTube)  
**🎙️ Apresentador:** Luciano Vasconcelos  

---

## 🔥 Sobre o Evento

Neste workshop, você aprenderá a construir um pipeline de ETL para extrair, transformar e carregar dados diretamente de uma API REST. Abordaremos cada etapa do processo, desde a autenticação na API até a persistência dos dados em um banco de dados local ou na nuvem.

**Objetivo:** Capacitar os participantes a desenvolver pipelines robustos de ETL utilizando Python, focando na integração com APIs de forma prática e eficiente.

---

## 🚀 O que será abordado?

1. **Introdução ao ETL:** Conceitos e aplicações.  
2. **Entendendo APIs REST:** Requisições HTTP (GET, POST), headers e autenticação.  
3. **Extração de Dados:** Uso de bibliotecas Python como `requests` e `httpx`.  
4. **Transformação dos Dados:** Limpeza, enriquecimento e formatação de dados com `pandas`.  
5. **Carregamento dos Dados:** Inserção em bancos de dados SQL e NoSQL.  
6. **Dicas de boas práticas:** Monitoramento, logs e tratamento de erros.

---

## 🛠️ Ferramentas e Tecnologias

- **Linguagem:** Python  
- **Bibliotecas:**  
  - `requests` ou `httpx` para integração com APIs  
  - `pandas` para manipulação de dados  
  - `SQLAlchemy` ou `sqlite3` para persistência de dados  
- **Outros:** Postman ou Insomnia para testar APIs.

---

## 💻 Pré-requisitos

Para acompanhar o evento, você precisará de:

1. **Python 3.8+** instalado na máquina.  
2. Editor de código (recomendado: VS Code ou PyCharm).  
3. Postman ou ferramenta similar para testar a API.  
4. Conhecimentos básicos de Python e manipulação de dados.  

---

## 📂 Estrutura do Repositório

```plaintext
etl-extracao-api-do-zero/
├── README.md
├── requirements.txt
├── scripts/
│   ├── extract.py
│   ├── transform.py
│   └── load.py
├── notebooks/
│   └── exploratory_analysis.ipynb
└── data/
    └── raw/
    └── processed/
```

- **`scripts/`:** Contém os códigos para cada etapa do ETL.  
- **`notebooks/`:** Notebooks para análises exploratórias e testes.  
- **`data/`:** Diretório para armazenar dados brutos e processados.

---

## 🎯 Público-Alvo

Entusiastas de dados, engenheiros de dados iniciantes, desenvolvedores e todos que desejam aprender a integrar APIs em pipelines de dados de forma prática e eficiente.

---

**📢 Participe ao vivo e leve seu pipeline ao próximo nível!**  
Clique aqui para ativar o lembrete: [Link do Evento no YouTube](#)  